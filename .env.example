# --- Google Cloud Configuration ---
GOOGLE_API_KEY="your_gemini_api_key_here"
GCP_PROJECT_ID="testing-444715"
GCP_LOCATION="me-central2"
GCP_BUCKET_NAME="meter-data-lake-testing-444715"
GCP_DATASET_ID="raw_meter_readings"
GCP_TABLE_ID="smart_meters_clean"

# --- ETL Performance Tuning ---
# Set to 'true' for low RAM environments (slower), 'false' for high RAM (faster)
ETL_LOW_MEMORY_MODE="true"
# Number of rows per Parquet group. Higher = better compression but more RAM.
ETL_ROW_GROUP_SIZE="50000"
# Compression codec: snappy (fast), zstd (good ratio), gzip (best ratio, slow), or none
PARQUET_COMPRESSION="snappy"
# Enable deterministic row hashing for deduplication (can be slow on huge files)
ETL_ENABLE_ROW_HASH="true"
# Number of rows to scan for schema inference
ETL_INFER_SCHEMA_LENGTH="1000"

# --- Cloud Upload Tuning ---
# Chunk size in MB. Higher = faster upload for high bandwidth, but uses more RAM.
# Default: 10 MB. For fast internet/RAM, try 50 or 100.
GCS_UPLOAD_CHUNK_SIZE_MB="10"
# Upload timeout in seconds. Increase if you have slow internet.
GCS_UPLOAD_TIMEOUT="300"
